### Upload library for DADA2 analysis ###
library(dada2)
library(phyloseq)
library(dplyr)
library(gridExtra)
library(readr)

#### Import seq ####
path <- ("./V3V4/Raw_data")
list.files(path) 
fnFs <- sort(list.files(path, pattern="R1.", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="R2.", full.names = TRUE)) 
sample.names <- sapply(strsplit(basename(fnFs), "_R1"),'[',1

#### Set a new patH ####
Set a new path to where the trimed fastq file will be uploaded
```{r echo=TRUE, eval=FALSE}
filt_path <- file.path(path, "Report")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste(sample.names, "_R_filt.fastq.gz"))
head(filtRs)

#### quality check #### 
QualityProfileFs <- list()
for(i in 1:length(fnFs)) {
  QualityProfileFs[[i]] <- list()
  QualityProfileFs[[i]][[1]] <- plotQualityProfile(fnFs[i])
}
pdf(file.path("Report","RawProfileForward.pdf"))
for(i in 1:length(fnFs)) {
  do.call("grid.arrange", QualityProfileFs[[i]])  
}
dev.off()
rm(QualityProfileFs)

QualityProfileRs <- list()
for(i in 1:length(fnRs)) {
  QualityProfileRs[[i]] <- list()
  QualityProfileRs[[i]][[1]] <- plotQualityProfile(fnRs[i])
}
pdf(file.path("Report","RawProfileReverse.pdf"))
for(i in 1:length(fnRs)) {
  do.call("grid.arrange", QualityProfileRs[[i]])  
}
dev.off()
rm(QualityProfileRs)

#### __Assign filtering parameters__ ####
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(260,215),
                     maxN=0, maxEE=c(3,5), truncQ=2, rm.phix=TRUE, trimLeft=c(17,21),
                     compress=TRUE, multithread=FALSE)
out

#### Let dada learn the error rates ####
errF <- learnErrors(filtFs, multithread=TRUE, MAX_CONSIST=20, verbose=TRUE, randomize=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE, MAX_CONSIST=20, verbose=TRUE, randomize=TRUE)
```
#### Combine all sequences replicates to a unique object ####
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)

#### renaming ####
#for further analysis, dada must have the same sample names for both F and R reads
names(derepFs) <- sample.names
names(derepRs) <- sample.names

#### Let dada make its magic ####
dadaFs <- dada(derepFs, errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
dadaFs[1]

#### Merge F and R reads to one amazing Sequence ####
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE,minOverlap = 8)
head(mergers[[1]])

#### Create an ASV table ####
seqtab_V3V4 <- makeSequenceTable(mergers)
dim(seqtab_V3V4 )
table(nchar(getSequences(seqtab_V3V4)))

#### remove chimeras ####
* calculation of the abundance as a proportion of the sequences that were after chimera removel
* Inspect distribution of sequence length
seqtab.nochim_V3V4 <- removeBimeraDenovo(seqtab_V3V4, method="consensus", multithread=TRUE, verbose=TRUE)
sum(seqtab.nochim_V3V4)/sum(seqtab_V3V4)
table(nchar(getSequences(seqtab.nochim_V3V4)))

#### remove singletons and 'junk' sequences ####
seqtab.nochim_V3V4_2 <- seqtab.nochim_V3V4[, nchar(colnames(seqtab.nochim_V3V4)) %in% c(400:430) & colSums(seqtab.nochim_V3V4) > 1]
dim(seqtab.nochim_V3V4_2)
summary(rowSums(seqtab.nochim_V3V4_2)/rowSums(seqtab.nochim_V3V4))

#### Summarizing the work flow in one table ####
getN <- function(x) sum(getUniques(x))
track_V3V4<- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim_V3V4),rowSums(seqtab.nochim_V3V4_2))
colnames(track_V3V4) <- c("input", "filtered", "denoisedF", "denoisedR", "merged","nonchim","table")
rownames(track_V3V4) <- sample.names
write.csv(track_V3V4,'./V3V4/Track_V3V4.csv')
saveRDS(track_V3V4,'./Track_V3V4.rds')

#### Assign taxonomy ####
taxa_V3V4 <- assignTaxonomy(seqtab.nochim_V3V4_2, "./Database/silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
taxa_V3V4 <- addSpecies(taxa_V3V4, "./Database/silva_species_assignment_v138.1.fa.gz") #assign species
head(taxa_V3V4)

#### get a readable tabulated format of the analysis ####
write.csv(t(seqtab.nochim_V3V4_2),"./V3V4/ASV_V3V4_seqtab.csv", quote = F)
write.csv(taxa_V3V4,"./V3V4/Taxonomy_V3V4_table.csv", quote = F)
dataps_V3V4=cbind(as.data.frame(t(seqtab.nochim_V3V4_2)), as.data.frame(taxa_V3V4))
write.csv(dataps_V3V4 ,"./V3V4/Taxonoy_ASV_V3V4_table.csv")

#### Save work enviroment ####
save.image("V3V4_dada2_Aug_runs.Rdata")
